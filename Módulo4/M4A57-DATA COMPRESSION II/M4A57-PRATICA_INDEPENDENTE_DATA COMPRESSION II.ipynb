{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática Independente: A maldição da dimensionalidade.\n",
    "\n",
    "#### Para entender o efeito da quantidade de dimensões na capacidade preditiva do modelo, vamos trabalhar com um classificador de notícias de dois jornais argentinos para tentar distingui-los com base no vocabulário que eles usam. <br />\n",
    "\n",
    "#### Para isso, vamos implementar um modelo de tipo `Naïve Bayes` com vetorização de tipo `TF-IDF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1: Carregue o arquivo `clarin.csv` em um dataframe, definindo para ele um atributo de classe `class = 0`. Carregue também o arquivo 'pagina12.csv’ em um dataframe separado, também criando um atributo de classe `class = 1`. Faça a concatenação dos dois dataframes.\n",
    "\n",
    "#### Realize uma análise exploratória, com uma limpeza dos dados, estudando a existência de dados nulos e fazendo a imputação de dados onde necessário, escolha o método que mais lhe convir.\n",
    "\n",
    "#### Remova as seções em que os dois jornais usam um vocabulário semelhante e de domínio muito específico, como esportes, por exemplo.\n",
    "\n",
    "#### Construa uma Corpus de documentos composto de uma coluna sobre a que iremos prever concatenando o título, resumo e corpo das diferentes notícias.\n",
    "\n",
    "#### Realize a normalização dos dados, convertendo o corpus de notícias para minúsculas, removendo acentos que possam gerar diferenças artificiais entre as palavras, removendo também a pontuação, deixando apenas palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Limpeza\n",
    "\n",
    "#### 1.1 Faltantes\n",
    "\n",
    "A partir do dataset observamos que os campos que provavelmente contêm vocabulário relevante são \"corpo\", \"título\" e \"resumo\".\n",
    "Remover da análise os registros que não possuem corpo ou título disponíveis e completar os resumos faltantes com um campo em branco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Suplementos relevantes\n",
    "\n",
    "Para melhorar a classificação, é conveniente retirar as seções em que os dois jornais usam um vocabulário semelhante e de domínio muito específico como, por exemplo, aqueles relacionados a esportes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Corpus\n",
    "\n",
    "Construa a coluna sobre a que iremos prever concatenando o título, resumo e corpo das diferentes notícias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Normalização do texto\n",
    "\n",
    "Primeiro, é conveniente passar todo o corpus a letras minúsculas.\n",
    "\n",
    "Para melhorar o classificador, é importante retirar todos os acentos que possam gerar diferenças artificiais entre as palavras, caso estejam colocados ou não. Hint: Usar o módulo unidecode\n",
    "\n",
    "Uma vez retirados os acentos, remover todos os sinais de pontuação para deixar somente palavras. Dica: usar uma expressão regular, por exemplo, r'([^\\s\\w]|_)+' para substituir tudo que não for palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 2: Vetorize o corpus resultante com a técnica `TF-IDF` e aplique um modelo `Naive Bayes` com um `split` simples entre os subconjuntos de treino e teste. \n",
    "\n",
    "#### Discuta qual é a dimensão da matriz de atributos e a precisão obtida. Plote também uma matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 3: Realize a redução da dimensionalidade do modelo apresentado.\n",
    "\n",
    "#### Considerando a relação entre o número de atributos e o número de casos de treinamento, discuta se, de acordo com a maldição da dimensionalidade, esta relação é um problema.\n",
    "\n",
    "#### Faça uso da lista de `stopwords `, com palavras do idioma espanhol que não têm um peso semântico significativo para a redução da dimensionalidade. Treinem novamente o modelo, removendo as `stopwords` contidas no arquivo \"stopwords.csv\".\n",
    "\n",
    "#### Discuta o que acontece com o número de dimensões da matriz de atributos e o que acontece com sua precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 4: Seguindo adiante na redução de dimensões, e considerando que modelo melhora quando removemos as `stopwords`, mas que ainda temos um número alto de dimensões, dada a quantidade de dados que temos. Considere:\n",
    "\n",
    "#### Para remover da análise as palavras que aparecem menos do que determinado número de vezes, a classe `TfidfVectorizer` tem um parâmetro `min_df`, que criar o vocabulário, ignora termos que tenham uma frequência de documento estritamente menor que o limite especificado.\n",
    "\n",
    "#### Definir o parâmetro `min_df = 6` e volte a executar o modelo. Discuta quanto se reduz a dimensão da matriz de atributos e quanto o desempenho do algoritmo é melhorado com a adoção desse procedimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
