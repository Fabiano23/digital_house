{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática Independente: A maldição da dimensionalidade.\n",
    "\n",
    "#### Para entender o efeito da quantidade de dimensões na capacidade preditiva do modelo, vamos trabalhar com um classificador de notícias de dois jornais argentinos para tentar distingui-los com base no vocabulário que eles usam. <br />\n",
    "\n",
    "#### Para isso, vamos implementar um modelo de tipo `Naïve Bayes` com vetorização de tipo `TF-IDF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1: Carregue o arquivo `clarin.csv` em um dataframe, definindo para ele um atributo de classe `class = 0`. Carregue também o arquivo 'pagina12.csv’ em um dataframe separado, também criando um atributo de classe `class = 1`. Faça a concatenação dos dois dataframes.\n",
    "\n",
    "#### Realize uma análise exploratória, com uma limpeza dos dados, estudando a existência de dados nulos e fazendo a imputação de dados onde necessário, escolha o método que mais lhe convir.\n",
    "\n",
    "#### Remova as seções em que os dois jornais usam um vocabulário semelhante e de domínio muito específico, como esportes, por exemplo.\n",
    "\n",
    "#### Construa uma Corpus de documentos composto de uma coluna sobre a que iremos prever concatenando o título, resumo e corpo das diferentes notícias.\n",
    "\n",
    "#### Realize a normalização dos dados, convertendo o corpus de notícias para minúsculas, removendo acentos que possam gerar diferenças artificiais entre as palavras, removendo também a pontuação, deixando apenas palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura dos dados\n",
    "clarin= pd.read_csv('clarin.csv')\n",
    "pagina12= pd.read_csv('pagina12.csv')\n",
    "\n",
    "#Retirando coluna desnecessária\n",
    "clarin.drop(columns= ['Unnamed: 0'], inplace= True)\n",
    "pagina12.drop(columns= ['Unnamed: 0'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105    0\n",
      "169    0\n",
      "Name: target, dtype: int64\n",
      "133    1\n",
      "86     1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Criando coluna com as classes 0 e 1 para os respectivos dataframes\n",
    "clarin= clarin.assign(target= 0)\n",
    "pagina12= pagina12.assign(target= 1)\n",
    "\n",
    "#Conferindo duas instâncias aleatórias dos dois dataframes na coluna target\n",
    "print(clarin['target'].sample(2))\n",
    "print(pagina12['target'].sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuerpo</th>\n",
       "      <th>fecha_hora</th>\n",
       "      <th>imagen</th>\n",
       "      <th>resumen</th>\n",
       "      <th>suplemento</th>\n",
       "      <th>titulo</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>El entrenador de la selección de Ecuador, Jo...</td>\n",
       "      <td>10/10/2017</td>\n",
       "      <td>//images.clarin.com/2017/10/10/rJiPDdcnb_930x5...</td>\n",
       "      <td>Jorge Célico fue suspendido por una discusión ...</td>\n",
       "      <td>/deportes/</td>\n",
       "      <td>Ecuador-Argentina: el entrenador local no podr...</td>\n",
       "      <td>http://www.clarin.com/deportes/seleccion-nacio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>En La Tempestad, Shakespeare incluyó una figur...</td>\n",
       "      <td>09 de octubre de 2017</td>\n",
       "      <td>https://images.pagina12.com.ar/styles/focal_16...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contratapa</td>\n",
       "      <td>Intelectuales siglo XXI</td>\n",
       "      <td>https://www.pagina12.com.ar/67931-intelectuale...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Si Argentina no llegara a ganarle a Ecuador ...</td>\n",
       "      <td>10/10/2017</td>\n",
       "      <td>//images.clarin.com/2017/10/05/SyO9jXV2b_930x5...</td>\n",
       "      <td>Se enfrentan en San Pablo, desde las 20:30, te...</td>\n",
       "      <td>/deportes/futbol/</td>\n",
       "      <td>Brasil-Chile por las Eliminatorias: horario, T...</td>\n",
       "      <td>http://www.clarin.com/deportes/futbol/brasil-c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cuerpo             fecha_hora  \\\n",
       "265    El entrenador de la selección de Ecuador, Jo...            10/10/2017    \n",
       "440  En La Tempestad, Shakespeare incluyó una figur...  09 de octubre de 2017   \n",
       "151    Si Argentina no llegara a ganarle a Ecuador ...            10/10/2017    \n",
       "\n",
       "                                                imagen  \\\n",
       "265  //images.clarin.com/2017/10/10/rJiPDdcnb_930x5...   \n",
       "440  https://images.pagina12.com.ar/styles/focal_16...   \n",
       "151  //images.clarin.com/2017/10/05/SyO9jXV2b_930x5...   \n",
       "\n",
       "                                               resumen         suplemento  \\\n",
       "265  Jorge Célico fue suspendido por una discusión ...         /deportes/   \n",
       "440                                                NaN         Contratapa   \n",
       "151  Se enfrentan en San Pablo, desde las 20:30, te...  /deportes/futbol/   \n",
       "\n",
       "                                                titulo  \\\n",
       "265  Ecuador-Argentina: el entrenador local no podr...   \n",
       "440                            Intelectuales siglo XXI   \n",
       "151  Brasil-Chile por las Eliminatorias: horario, T...   \n",
       "\n",
       "                                                   url  target  \n",
       "265  http://www.clarin.com/deportes/seleccion-nacio...       0  \n",
       "440  https://www.pagina12.com.ar/67931-intelectuale...       1  \n",
       "151  http://www.clarin.com/deportes/futbol/brasil-c...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenando os dois dataframes\n",
    "df= pd.concat([clarin, pagina12], ignore_index=True, axis= 0)\n",
    "df.sample(3, random_state= 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Limpeza\n",
    "\n",
    "#### 1.1 Faltantes\n",
    "\n",
    "A partir do dataset observamos que os campos que provavelmente contêm vocabulário relevante são \"corpo\", \"título\" e \"resumo\".\n",
    "Remover da análise os registros que não possuem corpo ou título disponíveis e completar os resumos faltantes com um campo em branco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo colunas com vocabulários não relevantes\n",
    "#df.drop(columns= ['imagen', 'url'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando valores nulos considerando colunas cuerpo e titulo\n",
    "df.dropna(axis=0, subset=['cuerpo', 'titulo', 'suplemento'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preenchendo valores nulos em resumen com uma string vazia\n",
    "df['resumen'].fillna(value= '', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Suplementos relevantes\n",
    "\n",
    "Para melhorar a classificação, é conveniente retirar as seções em que os dois jornais usam um vocabulário semelhante e de domínio muito específico como, por exemplo, aqueles relacionados a esportes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/lo-ultimo/', '/politica/', '/mundo/', '/sociedad/',\n",
       "       '/policiales/', '/ciudades/', '/opinion/', '/cartas_al_pais/',\n",
       "       '/cultura/', '/rural/', '/economia/', '/tecnologia/',\n",
       "       '/revista-enie/', '/viva/', '/br/', '/deportes/futbol/',\n",
       "       '/deportes/ascenso/', '/deportes/futbol-internacional/',\n",
       "       '/deportes/messi/', '/deportes/rugby/', '/deportes/tenis/',\n",
       "       '/deportes/automovilismo/', '/deportes/basquet/',\n",
       "       '/deportes/polideportivo/', '/deportes/turf/', '/deportes/boxeo/',\n",
       "       '/deportes/hockey/', '/deportes/', '/espectaculos/fama/',\n",
       "       '/espectaculos/tv/', '/espectaculos/cine/',\n",
       "       '/espectaculos/musica/', '/espectaculos/teatro/', '/si/',\n",
       "       '/espectaculos/', '/entremujeres/', '/autos/', '/buena-vida/',\n",
       "       '/viajes/', '/arq/', 'El país', 'El mundo', 'Sociedad', 'Deportes',\n",
       "       'Contratapa', 'Economía', 'Universidad', 'Plástica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['suplemento'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "supl_retirar= ['/deportes/futbol/', '/deportes/ascenso/', '/deportes/futbol-internacional/', \n",
    "          '/deportes/messi/', '/deportes/rugby/', '/deportes/tenis/', \n",
    "         '/deportes/automovilismo/', '/deportes/basquet/', \n",
    "          '/deportes/polideportivo/', '/deportes/turf/', '/deportes/boxeo/',\n",
    "         '/deportes/hockey/', '/deportes/', 'Deportes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/lo-ultimo/', '/politica/', '/mundo/', '/sociedad/',\n",
       "       '/policiales/', '/ciudades/', '/opinion/', '/cartas_al_pais/',\n",
       "       '/cultura/', '/rural/', '/economia/', '/tecnologia/',\n",
       "       '/revista-enie/', '/viva/', '/br/', '/espectaculos/fama/',\n",
       "       '/espectaculos/tv/', '/espectaculos/cine/',\n",
       "       '/espectaculos/musica/', '/espectaculos/teatro/', '/si/',\n",
       "       '/espectaculos/', '/entremujeres/', '/autos/', '/buena-vida/',\n",
       "       '/viajes/', '/arq/', 'El país', 'El mundo', 'Sociedad',\n",
       "       'Contratapa', 'Economía', 'Universidad', 'Plástica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe onde os valores da coluna suplemento estão nos valores que iremos retirar em supl_retirar\n",
    "mascara = df['suplemento'].isin(supl_retirar)\n",
    "\n",
    "#Mantendo os dados que não possuem o suplemento relacionado a esportes\n",
    "df= df[~mascara]\n",
    "\n",
    "#Conferindo quais valores em suplemento permaneceram\n",
    "df['suplemento'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Corpus\n",
    "\n",
    "Construa a coluna sobre a que iremos prever concatenando o título, resumo e corpo das diferentes notícias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soja: aumentó la superficie sembrada con semilla fiscalizada De acuerdo a los datos relevados por el Instituto Nacional de Semillas (INASE), el área declarada creció 4,25% y alcanzó el 36,3 % del área sembrada en todo el país.  El Ministerio de Agroindustria de la Nación, a través del Instituto Nacional de Semilla (INASE), publicó un informe acerca de la identificación de usuarios, variedades,\n",
      "\n",
      "Soja: aumentó la superficie sembrada con semilla fiscalizada De acuerdo a los datos relevados por el Instituto Nacional de Semillas (INASE), el área declarada creció 4,25% y alcanzó el 36,3 % del área sembrada en todo el país.  El Ministerio de Agroindustria de la Nación, a través del Instituto Nacional de Semilla (INASE), publicó un informe acerca de la identificación de usuarios, variedades,\n"
     ]
    }
   ],
   "source": [
    "#Criando coluna corpus com o título, o resumo e o corpo da notícia\n",
    "df= df.assign(corpus= df['titulo'] + ' ' + df['resumen'] + df['cuerpo'])\n",
    "\n",
    "#Conferindo concatenação feita utilizando primeira instância dos dados\n",
    "exemplo=  df['titulo'].values[0] + ' ' + df['resumen'].values[0] + df['cuerpo'].values[0]\n",
    "corpus_exemplo= df['corpus'].values[0]\n",
    "print(exemplo[:396])\n",
    "print()\n",
    "print(corpus_exemplo[:396])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Normalização do texto\n",
    "\n",
    "Primeiro, é conveniente passar todo o corpus a letras minúsculas.\n",
    "\n",
    "Para melhorar o classificador, é importante retirar todos os acentos que possam gerar diferenças artificiais entre as palavras, caso estejam colocados ou não. Hint: Usar o módulo unidecode\n",
    "\n",
    "Uma vez retirados os acentos, remover todos os sinais de pontuação para deixar somente palavras. Dica: usar uma expressão regular, por exemplo, r'([^\\s\\w]|_)+' para substituir tudo que não for palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo para minúsculas\n",
    "df['corpus']= df['corpus'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo acentos\n",
    "def remove_acentos(x):\n",
    "    '''Função que remove os acentos do corpus'''\n",
    "    x= unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x\n",
    "\n",
    "df['corpus']= df['corpus'].apply(lambda x: remove_acentos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo pontuações\n",
    "df['corpus']= df['corpus'].apply(lambda x: re.sub('[^A-Z a-z 0-9-]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo números\n",
    "df['corpus']= df['corpus'].apply(lambda x: ''.join([p for p in x if not p.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 2: Vetorize o corpus resultante com a técnica `TF-IDF` e aplique um modelo `Naive Bayes` com um `split` simples entre os subconjuntos de treino e teste. \n",
    "\n",
    "#### Discuta qual é a dimensão da matriz de atributos e a precisão obtida. Plote também uma matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciando objeto tfidf\n",
    "tfidf=  TfidfVectorizer().fit(df['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aadet</th>\n",
       "      <th>aaes</th>\n",
       "      <th>aal</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abaixo</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abajocalificacion</th>\n",
       "      <th>abajodivertido</th>\n",
       "      <th>abajotitulado</th>\n",
       "      <th>...</th>\n",
       "      <th>zoologico</th>\n",
       "      <th>zorra</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuain</th>\n",
       "      <th>zubizarreta</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucchinis</th>\n",
       "      <th>zurdo</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aadet      aaes  aal  aaron  abaixo  abajo  abajocalificacion  \\\n",
       "185  0.0    0.0  0.000000  0.0    0.0     0.0    0.0                0.0   \n",
       "270  0.0    0.0  0.047519  0.0    0.0     0.0    0.0                0.0   \n",
       "\n",
       "     abajodivertido  abajotitulado  ...  zoologico  zorra  zorro  zuain  \\\n",
       "185             0.0            0.0  ...        0.0    0.0    0.0    0.0   \n",
       "270             0.0            0.0  ...        0.0    0.0    0.0    0.0   \n",
       "\n",
       "     zubizarreta  zucchini  zucchinis  zurdo  zurich  zvyagintsev  \n",
       "185          0.0       0.0        0.0    0.0     0.0          0.0  \n",
       "270          0.0       0.0        0.0    0.0     0.0          0.0  \n",
       "\n",
       "[2 rows x 27910 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variáveis/palavras preditoras\n",
    "x_tfidf= tfidf.transform(df['corpus'])\n",
    "\n",
    "#Passando preditoras para dataframe\n",
    "X= pd.DataFrame(x_tfidf.toarray(), columns= tfidf.get_feature_names())\n",
    "\n",
    "#Variável resposta\n",
    "y= df['target']\n",
    "\n",
    "X.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: 27910\n"
     ]
    }
   ],
   "source": [
    "print(f'Colunas: {X.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 3: Realize a redução da dimensionalidade do modelo apresentado.\n",
    "\n",
    "#### Considerando a relação entre o número de atributos e o número de casos de treinamento, discuta se, de acordo com a maldição da dimensionalidade, esta relação é um problema.\n",
    "\n",
    "#### Faça uso da lista de `stopwords `, com palavras do idioma espanhol que não têm um peso semântico significativo para a redução da dimensionalidade. Treinem novamente o modelo, removendo as `stopwords` contidas no arquivo \"stopwords.csv\".\n",
    "\n",
    "#### Discuta o que acontece com o número de dimensões da matriz de atributos e o que acontece com sua precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 4: Seguindo adiante na redução de dimensões, e considerando que modelo melhora quando removemos as `stopwords`, mas que ainda temos um número alto de dimensões, dada a quantidade de dados que temos. Considere:\n",
    "\n",
    "#### Para remover da análise as palavras que aparecem menos do que determinado número de vezes, a classe `TfidfVectorizer` tem um parâmetro `min_df`, que criar o vocabulário, ignora termos que tenham uma frequência de documento estritamente menor que o limite especificado.\n",
    "\n",
    "#### Definir o parâmetro `min_df = 6` e volte a executar o modelo. Discuta quanto se reduz a dimensão da matriz de atributos e quanto o desempenho do algoritmo é melhorado com a adoção desse procedimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
