{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁTICA GUIADA: Introdução ao processo de Seleção de Recursos em SciKit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução\n",
    "\n",
    "#### Objetivo desta prática é introduzir alguns dos métodos para seleção de recursos implementados em `SciKit Learn`. Vamos nos concentrar em alguns dos mais comuns. \n",
    "\n",
    "#### Como foi mencionado, existem muitos métodos. Suas características podem ser consultadas na [documentação oficial do Scikit-Learn](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. “Famílias” de técnicas e métodos de seleção de recursos.\n",
    "\n",
    "#### Existem diferentes “famílias” de técnicas de seleção de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Recursos com baixa variância.\n",
    "\n",
    "#### Um primeiro caso, quase trivial, seria a remoção desses recursos ou características que não fornecem \"informações\" ao nosso conjunto de dados. Uma maneira de conseguir as informações é por meio da variância. \n",
    "\n",
    "#### Então, o que será feito é remover todos os recursos que tenham baixa variância (ou seja, baixa variabilidade). Isso será feito definindo um limiar abaixo do qual os recursos serão eliminados.\n",
    "\n",
    "#### Para isso, vamos importar as bibliotecas:\n",
    "\n",
    "* [`numpy`](https://numpy.org/), para manipularmos nossos dados.\n",
    "\n",
    "* [`pandas`](https://pandas.pydata.org/), para manipularmos nossos dados.\n",
    "\n",
    "* [`sklearn.feature_selection.VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn-feature-selection-variancethreshold), que opera como um seletor de recursos que remove todos os recursos com variação abaixo de um limiar pré-definido. \n",
    "\n",
    "* [`scipy.random`](https://numpy.org/doc/stable/reference/random/index.html), que produz números pseudoaleatórios usando combinações de um BitGenerator para criar sequências e um Gerador para usar essas sequências para amostrar de diferentes distribuições estatísticas\n",
    "\n",
    "* [`sklearn.datasets`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets), para carregarmos conjuntos de dados, incluindo métodos para carregar e buscar conjuntos de dados de referência populares, além de alguns geradores de dados artificiais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos carregar os datasets referentes [`iris`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris), com um conjunto de dados a respeito de espécies de flores e [`boston`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston), com dados a respeito da precificação de casas na cidade de Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "df1 = pd.DataFrame(np.concatenate((iris.data, \n",
    "                                   iris.target.reshape(-1,1)), \n",
    "                                  1), \n",
    "                   columns = iris.feature_names + ['species']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "iris = datasets.load_iris()\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "df1 = pd.DataFrame(np.concatenate((iris.data, iris.target.reshape(-1,1)),1),\n",
    "columns = iris.feature_names + ['species'])\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com o auxílio das funções:\n",
    "\n",
    "* [`apply()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html#pandas-dataframe-apply), que aplica uma função ao longo de um eixo do DataFrame.\n",
    "\n",
    "* [`np.numpy`](https://numpy.org/doc/stable/reference/generated/numpy.var.html), que calcula a variância ao longo do eixo especificado.\n",
    "\n",
    "#### Vemos que , se aplicarmos um 'limiar = 0.5' para a variância das colunas do dataset `df1`,  composto pela concatenação das atributos descritivos e do target desse dataset,   a única variável que deverá ser excluída será `'sepal_width'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0.681122\n",
       "sepal width (cm)     0.188713\n",
       "petal length (cm)    3.095503\n",
       "petal width (cm)     0.577133\n",
       "species              0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.apply(np.var, \n",
    "          axis = 0\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df1.apply(np.var,0)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos começar nossa seleção de atributos aplicando a função [`VarianceThreshold{}`](https://scikit-learn.org/stable/modules/feature_selection.html), que realiza uma abordagem básica para seleção de recursos, removendo todos os recursos cuja variação não atende a algum limite pré-definido.\n",
    "\n",
    "#### Este algoritmo de seleção de recursos olha apenas para os recursos (X), não as saídas desejadas (y) e pode, portanto, ser usado para aprendizado não supervisionado.\n",
    "\n",
    "#### Depois de removermos atributos que não atendem a nossa condição para a variância, ajustamos os pontos do dataset `df1`, com o método [`.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold.fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fet_sel = VarianceThreshold(threshold = 0.5)\n",
    "fet_sel.fit(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "fet_sel = VarianceThreshold(threshold = 0.5)\n",
    "fet_sel.fit(df1)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando o método [`get_support`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold.get_support), que retorna uma máscara, ou índice inteiro, dos recursos selecionados,  podemos consultar uma matriz booleana que define as variáveis que não foram excluídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fet_sel.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "fet_sel.get_support()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando o método [`.columns[]`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns), podemos checar aquelas que passaram no teste de limite inferior de variância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'petal length (cm)', 'petal width (cm)',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns[fet_sel.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df1.columns[fet_sel.get_support()]\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos gerar um novo dataframe apenas com as colunas que crumpriram a condição imposta pelo limite inferiore de variância,  para isso podemos simplesmente invocar o método [`.transform ()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html#pandas-dataframe-transform), que na situação a seguir, vai aplicar ao dataframe `df1` o ajuste `fet_sel` que trás a aplicação do limite de variância. Para os nomes das colunas, no parâmetro `columns`, podes repetir a aplicação do método `.columns()`, que traz as máscaras  com variância superior ao limite imposto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  petal length (cm)  petal width (cm)  species\n",
       "0                5.1                1.4               0.2      0.0\n",
       "1                4.9                1.4               0.2      0.0\n",
       "2                4.7                1.3               0.2      0.0\n",
       "3                4.6                1.5               0.2      0.0\n",
       "4                5.0                1.4               0.2      0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_reduced = pd.DataFrame(fet_sel.transform(df1), \n",
    "                           columns = df1.columns[fet_sel.get_support()]\n",
    "                          )\n",
    "df1_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df1_reduced = pd.DataFrame(fet_sel.transform(df1), \n",
    "                           columns = df1.columns[fet_sel.get_support()]\n",
    "                          )\n",
    "df1_reduced.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style = \"color:blue\">Prática Independente.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repita a operação de redução de atributos por meio do estabelecimento de um limite inferior `var = 1.0` para a variância dos dados do dataset `Boston`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df2 = pd.DataFrame(np.concatenate((boston.data, \n",
    "                                   boston.target.reshape(-1,1)), \n",
    "                                  1\n",
    "                                 ), \n",
    "                   columns = list(boston.feature_names) + ['price']\n",
    "                  )\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df2.apply(np.var, \n",
    "          axis = 0\n",
    "         )\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "fetdf2_sel = VarianceThreshold(threshold = 1.0)\n",
    "fetdf2_sel.fit(df2)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "fetdf2_sel.get_support()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df2.columns[fetdf2_sel.get_support()]\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df2_reduced = pd.DataFrame(fetdf2_sel.transform(df2), \n",
    "                           columns = df2.columns[fetdf2_sel.get_support()]\n",
    "                          )\n",
    "df2_reduced.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Seleção de Recursos univariada\n",
    "\n",
    "#### Como o nome indica, esses [métodos](https://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html) procuram selecionar recursos, com base em diferentes testes univariados (F, qui-quadrado, etc.).\n",
    "\n",
    "#### A seleção univariada de recursos escolhe os melhores recursos com base em [testes estatísticos univariados](https://towardsdatascience.com/exploring-univariate-data-e7e2dc8fde80) e pode ser entendida como um passo no processo de pré-processamento para o cálculo de um estimador.\n",
    "\n",
    "#### Vamos importar as seguintes bibliotecas:\n",
    "\n",
    "* [`sklearn.feature_selection.f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html), que calcula o valor [ANOVA F](https://towardsdatascience.com/anova-for-feature-selection-in-machine-learning-d9305e228476) para a amostra fornecida.\n",
    "\n",
    "* [`sklearn.feature_selection.f_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn-feature-selection-f-regression), que gera um modelo linear para testar o efeito individual de cada um dos muitos regressores. lembre-se que esta é uma função de pontuação a ser usada em um procedimento de seleção de recurso, não um procedimento de seleção de recurso independente.\n",
    "\n",
    "* [`sklearn.feature_selection.SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html). Vamos continuar usando o conjunto de dados anterior. Este método usa dois argumentos:\n",
    "\n",
    "    - `score_func`: Função que toma dois arrays `X` e `y`, e retornando um par de arranjos (pontuações, pvalues) ou um único arranjo com pontuações.\n",
    "\n",
    "    - `k`: A quantidade de “melhores” recursos que serão selecionados.\n",
    "\n",
    "#### Para facilitar o desenvolvimento, criamos uma função `select_kbest_reg` que executa os métodos, extrai os atributos e imprime os resultados. \n",
    "\n",
    "* A função usa um dataframe como entrada, o target a ser estudado e o número de atributos  a serem mantidos.\n",
    "\n",
    "* Depois, instancia o método `SelectKBest` com os parâmetros `score_func = f_regression` e `k = 2`\n",
    "\n",
    "* Realiza o [`.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest.fit) do método, executando a função de pontuação em `(X, y)` e obtendo os recursos apropriados.\n",
    "\n",
    "* Salva os resultados (`scores`, `pvalues`, `get_support` e as colunas) em um dataframe e os retorna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F Score</th>\n",
       "      <th>P Value</th>\n",
       "      <th>Support</th>\n",
       "      <th>Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>601.617871</td>\n",
       "      <td>5.081103e-88</td>\n",
       "      <td>True</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>471.846740</td>\n",
       "      <td>2.487229e-74</td>\n",
       "      <td>True</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.105543</td>\n",
       "      <td>1.609509e-34</td>\n",
       "      <td>True</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.954883</td>\n",
       "      <td>4.900260e-31</td>\n",
       "      <td>True</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>141.761357</td>\n",
       "      <td>5.637734e-29</td>\n",
       "      <td>False</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.591480</td>\n",
       "      <td>7.065042e-24</td>\n",
       "      <td>False</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.486115</td>\n",
       "      <td>1.173987e-19</td>\n",
       "      <td>False</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85.914278</td>\n",
       "      <td>5.465933e-19</td>\n",
       "      <td>False</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.477459</td>\n",
       "      <td>1.569982e-18</td>\n",
       "      <td>False</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.257642</td>\n",
       "      <td>5.713584e-17</td>\n",
       "      <td>False</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.054229</td>\n",
       "      <td>1.318113e-14</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.579570</td>\n",
       "      <td>1.206612e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.971512</td>\n",
       "      <td>7.390623e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F Score       P Value  Support Attribute\n",
       "12  601.617871  5.081103e-88     True     LSTAT\n",
       "5   471.846740  2.487229e-74     True        RM\n",
       "10  175.105543  1.609509e-34     True   PTRATIO\n",
       "2   153.954883  4.900260e-31     True     INDUS\n",
       "9   141.761357  5.637734e-29    False       TAX\n",
       "4   112.591480  7.065042e-24    False       NOX\n",
       "0    89.486115  1.173987e-19    False      CRIM\n",
       "8    85.914278  5.465933e-19    False       RAD\n",
       "6    83.477459  1.569982e-18    False       AGE\n",
       "1    75.257642  5.713584e-17    False        ZN\n",
       "11   63.054229  1.318113e-14    False         B\n",
       "7    33.579570  1.206612e-08    False       DIS\n",
       "3    15.971512  7.390623e-05    False      CHAS"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "\n",
    "df2 = pd.DataFrame(np.concatenate((boston.data, \n",
    "                                   boston.target.reshape(-1,1)), \n",
    "                                  1\n",
    "                                 ), \n",
    "                   columns = list(boston.feature_names) + ['price']\n",
    "                  )\n",
    "\n",
    "def select_kbest_reg(data_frame, target, k = 2):\n",
    "    \"\"\"\n",
    "    Selecionando recursos K-Best para regressão\n",
    "    :param data_frame: Um dataframe com dados\n",
    "    :param target: target no dataframe\n",
    "    :param k: quantidade desejada de recursos\n",
    "    :retorna um dataframe chamado feature_scores com os scores para cada recurso\n",
    "    \"\"\"\n",
    "    feat_selector = SelectKBest(score_func = f_regression, \n",
    "                                k = k\n",
    "                               )\n",
    "    _ = feat_selector.fit(data_frame.drop(target, \n",
    "                                          axis = 1), \n",
    "                          data_frame[target]\n",
    "                         )\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[\"F Score\"] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, \n",
    "                                               axis = 1).columns\n",
    "    \n",
    "    return feat_scores\n",
    "\n",
    "kbest_feat = select_kbest_reg(df2, \n",
    "                              \"price\", \n",
    "                              k = 4\n",
    "                             )\n",
    "kbest_feat = kbest_feat.sort_values([\"F Score\", \n",
    "                                     \"P Value\"], \n",
    "                                    ascending = [False, \n",
    "                                                 False]\n",
    "                                   )\n",
    "kbest_feat\n",
    "#kbest_feat['Attribute'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "\n",
    "df2 = pd.DataFrame(np.concatenate((boston.data, \n",
    "                                   boston.target.reshape(-1,1)), \n",
    "                                  1\n",
    "                                 ),\n",
    "\n",
    "columns = list(boston.feature_names) + ['price'])\n",
    "\n",
    "def select_kbest_reg(data_frame, target, k = 2):\n",
    "    \"\"\"\n",
    "    Selecionando recursos K-Best para regressão\n",
    "    :param data_frame: Um dataframe com dados\n",
    "    :param target: target no dataframe\n",
    "    :param k: quantidade desejada de recursos\n",
    "    :retorna um dataframe chamado feature_scores com os scores para cada recurso\n",
    "    \"\"\"\n",
    "    feat_selector = SelectKBest(score_func = f_regression, \n",
    "                                k = k\n",
    "                               )\n",
    "    _ = feat_selector.fit(data_frame.drop(target, \n",
    "                                          axis = 1), \n",
    "                          data_frame[target]\n",
    "                         )\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[\"F Score\"] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, \n",
    "                                               axis = 1).columns\n",
    "    \n",
    "    return feat_scores\n",
    "\n",
    "kbest_feat = select_kbest_reg(df2, \n",
    "                              \"price\", \n",
    "                              k = 4\n",
    "                             )\n",
    "kbest_feat = kbest_feat.sort_values([\"F Score\", \n",
    "                                     \"P Value\"], \n",
    "                                    ascending = [False, \n",
    "                                                 False]\n",
    "                                   )\n",
    "kbest_feat\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe na aplicação dos seguintes atributos e método ao objeto `feat_selector`:\n",
    "\n",
    "* `.scores_`, que retorna a pontuação da seleção;\n",
    "* `.pvalues_`, que retorna o pvalor para os scores dos atributos selecionados;\n",
    "* `.get_support()`, para obtermos uma máscara, ou índice inteiro, dos recursos selecionados.\n",
    "\n",
    "#### Pode ser visto, portanto, que, se quisermos selecionar as 10 melhores variáveis, elas serão `'LSTAT'`,`'RM'`, `'PTRATIO'` e `'INDUS'`.\n",
    "\n",
    "#### A seguir podemos testar o atributo `Support`, que recebe a máscara `.get_support()` com `True` ou `False`, para os atributos que serão selecionados.\n",
    "\n",
    "#### Até esse momento os resultados do `SelectKBest` foram apenas impressos, para realizarmos a seleção efetivamente devemos criar um dataframe com os atributos que passam na seleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>INDUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.98</td>\n",
       "      <td>6.575</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "      <td>6.421</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.03</td>\n",
       "      <td>7.185</td>\n",
       "      <td>17.8</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.94</td>\n",
       "      <td>6.998</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.33</td>\n",
       "      <td>7.147</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT     RM  PTRATIO  INDUS\n",
       "0   4.98  6.575     15.3   2.31\n",
       "1   9.14  6.421     17.8   7.07\n",
       "2   4.03  7.185     17.8   7.07\n",
       "3   2.94  6.998     18.7   2.18\n",
       "4   5.33  7.147     18.7   2.18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = kbest_feat.loc[kbest_feat['Support'] == True, \n",
    "                        'Attribute'\n",
    "                       ]\n",
    "#select\n",
    "df2_reduced = df2[select]\n",
    "df2_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "select = kbest_feat.loc[kbest_feat['Support'] == True,'Attribute']\n",
    "df2_reduced = df2[select]\n",
    "df2_reduced.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se quisermos trabalhar com um problema de classificação, podemos simplesmente converter o `score_func` a alguma função de pontuação adequada:\n",
    "\n",
    "- ` f_classif`, \n",
    "- `chi2`, \n",
    "\n",
    "#### ou usar algumas das funções que fazem pontuação com base em métricas como:\n",
    "\n",
    "* [` SelectFpr`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html), que funciona como um filtro, selecionando os pvalores abaixo de alfa com base em um [teste FPR](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/feature_scoring.html) ([False Positive](https://www.statisticshowto.com/false-positive-definition-and-examples/) Rate).\n",
    "\n",
    "* [` SelectFdr`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html), que seleciona os pvalores para uma taxa estimada de descoberta falsa ([False Discovery Rate](https://www.statisticshowto.com/false-discovery-rate/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uma outra possibilidade é a aplicação do método: \n",
    "\n",
    "* [`SelectKPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html), que seleciona os atributos de acordo com um percentual das pontuações mais altas.\n",
    "\n",
    "#### Esse método seleciona os recursos com base nos percentis (definidos pelo usuário) das pontuações máximas. Aqui vamos aplicar como parâmetro `score_func` o teste de regressão linear univariada [`f_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression),  um modelo linear para testar o efeito individual de cada um dos muitos regressores.\n",
    "\n",
    "#### Depois disso o método [`.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile.fit), aplicado ao objeto de seleção de atributos `feat_selector`, executa a função de pontuação em `(X, y)` e obtém os recursos apropriados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "def select_percentile(data_frame, target, percentile = 15):\n",
    "\n",
    "    feat_selector = SelectPercentile(score_func = f_regression, \n",
    "                                     percentile = percentile\n",
    "                                    )\n",
    "    _ = feat_selector.fit(data_frame.drop(target, \n",
    "                                          axis = 1), \n",
    "                          data_frame[target]\n",
    "                         )\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[\"F Score\"] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, \n",
    "                                               axis = 1\n",
    "                                              ).columns\n",
    "    \n",
    "    return feat_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "def select_percentile(data_frame, target, percentile = 15):\n",
    "\n",
    "    feat_selector = SelectPercentile(score_func = f_regression, \n",
    "                                     percentile = percentile\n",
    "                                    )\n",
    "    _ = feat_selector.fit(data_frame.drop(target, \n",
    "                                          axis = 1), \n",
    "                          data_frame[target]\n",
    "                         )\n",
    "    \n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[\"F Score\"] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n",
    "    \n",
    "    return feat_scores\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos então submeter o dataframe `df2`, que criamos anteriormente, com o target `price` e procurar por  $20\\%$ dos atributos a serem mantidos.\n",
    "\n",
    "#### Em seguida, podemos ordenar os resultados por `\"F Score\"`, `\"P Value\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F Score</th>\n",
       "      <th>P Value</th>\n",
       "      <th>Support</th>\n",
       "      <th>Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>601.617871</td>\n",
       "      <td>5.081103e-88</td>\n",
       "      <td>True</td>\n",
       "      <td>LSTAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>471.846740</td>\n",
       "      <td>2.487229e-74</td>\n",
       "      <td>True</td>\n",
       "      <td>RM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.105543</td>\n",
       "      <td>1.609509e-34</td>\n",
       "      <td>True</td>\n",
       "      <td>PTRATIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.954883</td>\n",
       "      <td>4.900260e-31</td>\n",
       "      <td>False</td>\n",
       "      <td>INDUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>141.761357</td>\n",
       "      <td>5.637734e-29</td>\n",
       "      <td>False</td>\n",
       "      <td>TAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.591480</td>\n",
       "      <td>7.065042e-24</td>\n",
       "      <td>False</td>\n",
       "      <td>NOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.486115</td>\n",
       "      <td>1.173987e-19</td>\n",
       "      <td>False</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85.914278</td>\n",
       "      <td>5.465933e-19</td>\n",
       "      <td>False</td>\n",
       "      <td>RAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.477459</td>\n",
       "      <td>1.569982e-18</td>\n",
       "      <td>False</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.257642</td>\n",
       "      <td>5.713584e-17</td>\n",
       "      <td>False</td>\n",
       "      <td>ZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.054229</td>\n",
       "      <td>1.318113e-14</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.579570</td>\n",
       "      <td>1.206612e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.971512</td>\n",
       "      <td>7.390623e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>CHAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       F Score       P Value  Support Attribute\n",
       "12  601.617871  5.081103e-88     True     LSTAT\n",
       "5   471.846740  2.487229e-74     True        RM\n",
       "10  175.105543  1.609509e-34     True   PTRATIO\n",
       "2   153.954883  4.900260e-31    False     INDUS\n",
       "9   141.761357  5.637734e-29    False       TAX\n",
       "4   112.591480  7.065042e-24    False       NOX\n",
       "0    89.486115  1.173987e-19    False      CRIM\n",
       "8    85.914278  5.465933e-19    False       RAD\n",
       "6    83.477459  1.569982e-18    False       AGE\n",
       "1    75.257642  5.713584e-17    False        ZN\n",
       "11   63.054229  1.318113e-14    False         B\n",
       "7    33.579570  1.206612e-08    False       DIS\n",
       "3    15.971512  7.390623e-05    False      CHAS"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_feat = select_percentile(df2, \n",
    "                             \"price\", \n",
    "                             percentile = 20\n",
    "                            )\n",
    "per_feat = per_feat.sort_values([\"F Score\", \"P Value\"], \n",
    "                                ascending = [False, \n",
    "                                             False\n",
    "                                            ]\n",
    "                               )\n",
    "per_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "per_feat = select_percentile(df2, \n",
    "                             \"price\", \n",
    "                             percentile = 20\n",
    "                            )\n",
    "per_feat = per_feat.sort_values([\"F Score\", \"P Value\"], \n",
    "                                ascending = [False, \n",
    "                                             False\n",
    "                                            ]\n",
    "                               )\n",
    "per_feat\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os atributos suportados são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.98</td>\n",
       "      <td>6.575</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "      <td>6.421</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.03</td>\n",
       "      <td>7.185</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.94</td>\n",
       "      <td>6.998</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.33</td>\n",
       "      <td>7.147</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT     RM  PTRATIO\n",
       "0   4.98  6.575     15.3\n",
       "1   9.14  6.421     17.8\n",
       "2   4.03  7.185     17.8\n",
       "3   2.94  6.998     18.7\n",
       "4   5.33  7.147     18.7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = per_feat.loc[per_feat['Support'] == True, \n",
    "                        'Attribute'\n",
    "                       ]\n",
    "#select\n",
    "per_feat_reduced = df2[select]\n",
    "per_feat_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "select = per_feat.loc[per_feat['Support'] == True, \n",
    "                        'Attribute'\n",
    "                       ]\n",
    "#select\n",
    "per_feat_reduced = df2[select]\n",
    "per_feat_reduced.head()\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Eliminação Recursiva de Recursos (RFE)\n",
    "\n",
    "#### Este método usa como entrada um estimador externo para tentar quantificar o peso (importância) de cada recurso. O método elimina recursos sucessivamente para ficar com conjuntos de recursos cada vez menores.\n",
    "\n",
    "#### Em primeira instância, o método treina o estimador sobre o total de recursos e a importância de cada recurso é quantificada através de algum atributo do tipo `coef_` ou `feature_importance`. Elimina o recurso menos importante do conjunto e volta a treinar com os restantes. O processo é repetido recursivamente até que seja atingido o número de recursos previamente definido.\n",
    "\n",
    "#### Para a aplicação do método método [`Recursive Feature Elimination`](https://machinelearningmastery.com/rfe-feature-selection-in-python/), vamos importar a biblioteca:\n",
    "\n",
    "* [`sklearn.feature_selection.RFE`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html), que realiza uma classificação de atributos, através de uma eliminação recursiva de recursos. Seu objetivo é selecionar recursos considerando recursivamente conjuntos cada vez menores de desses recursos.\n",
    "\n",
    "usa os seguintes argumentos:\n",
    "\n",
    "- `estimator`, que é um estimador de aprendizado supervisionado com um método de ajuste (fit) que fornece informações sobre a importância do recurso por meio de um atributo `coef_` ou por meio de um atributo `feature_importances_`\n",
    "\n",
    "- `n_features_to_select`, que é a quantidade de recursos a serem selecionados.\n",
    "\n",
    "- `steps`, corresponde ao número (inteiro) de recursos a serem removidos em cada iteração.\n",
    "\n",
    "#### Vamos também importar a biblioteca:\n",
    "\n",
    "* [`sklearn.svm.SVR`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html), usada para especificar a função de `Kernel` a ser usada no algorítmo, devendo ser do tipo ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’ ou ‘precomputed’.\n",
    "\n",
    "#### Criamos então uma função `ref_feature_select`, que recebe o conjunto de atributos, os tagets e o número de recursos a serem selecionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def ref_feature_select(data_frame, target_name, n_feats = 20 ):\n",
    "    estimator = SVR(kernel = 'linear')\n",
    "    selector = RFE(estimator, \n",
    "                   n_features_to_select = n_feats, \n",
    "                   step = 1\n",
    "                  )\n",
    "    _ = selector.fit(data_frame.drop(target_name, \n",
    "                                     axis = 1), \n",
    "                     data_frame[target_name]\n",
    "                    )\n",
    "\n",
    "    scores = pd.DataFrame()\n",
    "    scores[\"Attribute Name\"] = data_frame.drop(target_name, \n",
    "                                               axis = 1).columns\n",
    "    scores[\"Ranking\"] = selector.ranking_\n",
    "    scores[\"Support\"] = selector.support_\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def ref_feature_select(data_frame, target_name, n_feats = 20 ):\n",
    "    estimator = SVR(kernel = 'linear')\n",
    "    selector = RFE(estimator, \n",
    "                   n_features_to_select = n_feats, \n",
    "                   step = 1\n",
    "                  )\n",
    "    _ = selector.fit(data_frame.drop(target_name, \n",
    "                                     axis = 1), \n",
    "                     data_frame[target_name]\n",
    "                    )\n",
    "\n",
    "    scores = pd.DataFrame()\n",
    "    scores[\"Attribute Name\"] = data_frame.drop(target_name, \n",
    "                                               axis = 1).columns\n",
    "    scores[\"Ranking\"] = selector.ranking_\n",
    "    scores[\"Support\"] = selector.support_\n",
    "\n",
    "    return scores\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depois disso podemos apresentar aplicar a função `ref_feature_select` o dataframe `df2`, com o target `'price'` para a seleção de 5 atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute Name</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute Name  Ranking  Support\n",
       "0            CRIM        3    False\n",
       "1              ZN        5    False\n",
       "2           INDUS        4    False\n",
       "3            CHAS        1     True\n",
       "4             NOX        1     True\n",
       "5              RM        1     True\n",
       "6             AGE        6    False\n",
       "7             DIS        2    False\n",
       "8             RAD        8    False\n",
       "9             TAX        9    False\n",
       "10        PTRATIO        1     True\n",
       "11              B        7    False\n",
       "12          LSTAT        1     True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_feature_select(df2,\n",
    "                   'price', \n",
    "                   n_feats = 5\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "ref_feature_select(df2,\n",
    "                   'price', \n",
    "                   n_feats = 5\n",
    "                  )\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entretanto, o número de recursos a serem mantidos não pode ser escolhido arbitrariamente, mas de forma objetiva. Para isso vamos aplicar a técnica de validação cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Felizmente, existe um método que nos permite selecionar, através de Validação Cruzada, o número de recursos a serem mantidos.\n",
    "\n",
    "\n",
    "#### Para isso vamos importar a biblioteca [`sklearn.feature_selection.RFECV`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html), que realiza uma classificação de recursos com eliminação recursiva dos mesmos e seleção com validação cruzada do melhor número de atributos. O método `RFECV` usa os seguintes argumentos:\n",
    "\n",
    "- `estimator`, que é um estimador de aprendizado supervisionado com um método de ajuste que fornece informações sobre a importância do recurso por meio de um atributo `coef_` ou por meio de um atributo `feature_importances_`.   \n",
    "   \n",
    "- `steps`, que corresponds ao número de recursos a serem removidos em cada iteração.\n",
    "\n",
    "- `cv`, que determina a estratégia de divisão de validação cruzada.\n",
    "   \n",
    "[`sklearn.model_selection.KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), que fornece índices de treino/teste para dividir dados em conjuntos de treino e de teste. Divide o conjunto de dados em `k` dobras consecutivas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Começamos definindo nossa estratégia de validação cruzada a partir de um objeto `kf` para estabelecer o número de dobras a serem aplicadas aos subconjuntos dos dados, famos isso com a função [`KFold()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), que fornece índices de para dividir os dados em conjuntos de treino / teste e divide o conjunto de dados em `k` dobras consecutivas.\n",
    "\n",
    "#### Depois instanciando um estimador `estimator` com o auxílio da função [`SVR()`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html), que realiza uma [regressão](https://towardsdatascience.com/an-introduction-to-support-vector-regression-svr-a3ebc1672c2) com vetor de suporte, a partir dos parâmetros:\n",
    "\n",
    "- `C`, que regula a intensidade da regularização aplicada.\n",
    "    \n",
    "- `epsilon`, que especifica a margem épsilon dentro da qual nenhuma penalidade está associada na função de perda de treinamento com pontos previstos dentro de uma distância épsilon do valor real.    \n",
    "\n",
    "#### A função [`RFECV()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) realiza e classificação de atributos com eliminação recursiva de recursos através da seleção por meio da validação cruzada do melhor número de recursos.\n",
    "\n",
    "#### Por fim, o método [`fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV.fit) é aplica ao conjunto de atributos restantes, para ajustá-los ao modelo de regressão e sintonizar o número de atributos selecionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, \n",
    "           shuffle = True)\n",
    "\n",
    "estimator = SVR(kernel = 'linear', \n",
    "                C = 1.0, \n",
    "                epsilon = 0.1\n",
    "               )\n",
    "\n",
    "selector = RFECV(estimator, \n",
    "                 step = 1, \n",
    "                 scoring = 'neg_mean_squared_error', \n",
    "                 verbose = 2\n",
    "                )\n",
    "\n",
    "selector.fit(df2.drop('price', \n",
    "                      axis = 1), \n",
    "             df2['price']\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "kf = KFold(n_splits = 10, \n",
    "           shuffle = True)\n",
    "\n",
    "estimator = SVR(kernel = 'linear', \n",
    "                C = 1.0, \n",
    "                epsilon = 0.1\n",
    "               )\n",
    "\n",
    "selector = RFECV(estimator, \n",
    "                 step = 1, \n",
    "                 scoring = 'neg_mean_squared_error', \n",
    "                 verbose = 2\n",
    "                )\n",
    "\n",
    "selector.fit(df2.drop('price', \n",
    "                      axis = 1), \n",
    "             df2['price']\n",
    "            )\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos saber quais variáveis são selecionadas após o processo de validação cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('price', \n",
    "         axis = 1).loc[:, selector.support_].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "df2.drop('price', \n",
    "         axis = 1).loc[:, selector.support_].columns\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Também podemos ver qual é o score (cross-validado) de cada uma das variáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selector.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "selector.grid_scores_\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seleção de recurso como parte de um pipeline\n",
    "\n",
    "#### A introdução de um processo de seleção de recursos dentro de um pipeline é direta e pode ser feita a partir da importação das bibliotecas:\n",
    "\n",
    "* [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), que canaliza as transformações para a obtenção de um estimador final, por meio de uma aplicação seqüêncial de transformações.\n",
    "\n",
    "* [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), que realiza uma pesquisa sobre valores de parâmetros especificados para um estimador.\n",
    "\n",
    "#### Essa célula leva algum tempo para rodar, ~15 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estim = SVR(kernel = 'linear', \n",
    "            C = 1.0,\n",
    "            epsilon = 0.1\n",
    "           )\n",
    "\n",
    "select = RFE(estim, \n",
    "             step = 1, \n",
    "             verbose = 1\n",
    "            )\n",
    "\n",
    "pipe = Pipeline([('feat_sel', select), \n",
    "                 ('reg', estim)\n",
    "                ]\n",
    "               )\n",
    "\n",
    "param_grid = {'feat_sel__n_features_to_select' : np.arange(1, len(df2.columns)), \n",
    "              'reg__C' : [0.1, 1, 10]}\n",
    "\n",
    "estim = GridSearchCV(pipe, \n",
    "                     param_grid, \n",
    "                     verbose = 1, \n",
    "                     n_jobs = 1\n",
    "                    )\n",
    "\n",
    "estim.fit(df2.drop('price', axis = 1), \n",
    "          df2['price'] \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "kf = KFold(n_splits = 3, \n",
    "           shuffle = True\n",
    "          )\n",
    "\n",
    "estim = SVR(kernel = 'linear', \n",
    "            C = 1.0,\n",
    "            epsilon = 0.1\n",
    "           )\n",
    "\n",
    "select = RFE(estim, \n",
    "             step = 1, \n",
    "             verbose = 1\n",
    "            )\n",
    "\n",
    "pipe = Pipeline([('feat_sel', select), \n",
    "                 ('reg', estim)\n",
    "                ]\n",
    "               )\n",
    "\n",
    "param_grid = {'feat_sel__n_features_to_select' : np.arange(1, len(df2.columns)), \n",
    "              'reg__C' : [0.1, 1, 10]}\n",
    "\n",
    "estim = GridSearchCV(pipe, \n",
    "                     param_grid, \n",
    "                     verbose = 1, \n",
    "                     n_jobs = 1\n",
    "                    )\n",
    "\n",
    "estim.fit(df2.drop('price', axis = 1), \n",
    "          df2['price'] \n",
    "         )\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A função `GridSearchCV` possui um atributo [`cv_results_`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), que trás um dicionário com chaves como cabeçalhos de coluna e valores como colunas, que podem ser importados para um `DataFrame` do `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(estim.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "pd.DataFrame(estim.cv_results_)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A função `GridSearchCV` também possui um atributo [`best_estimator_`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), que trás o estimador que foi escolhido pela pesquisa, ou seja estimador que deu a pontuação mais alta (ou a menor perda, se especificado) nos dados deixados de fora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style = \"color:red\">Código Original.</span>\n",
    "<!---\n",
    "estim.best_estimator_\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
